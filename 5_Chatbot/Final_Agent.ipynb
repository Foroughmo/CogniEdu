{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a141271-18b9-432a-9ca8-d194101f32dd",
   "metadata": {},
   "source": [
    "# Agent Workflow with all Tools Defined and an Example Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae7235f7-0d47-40e5-9a83-ed136b96d768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "from google.cloud import storage\n",
    "from vertexai.language_models import TextEmbeddingModel, TextGenerationModel\n",
    "import chromadb\n",
    "import io\n",
    "import vertexai\n",
    "import re\n",
    "import uuid\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import VertexAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_google_vertexai import ChatVertexAI, VertexAIEmbeddings\n",
    "import warnings\n",
    "from PyPDF2.errors import PdfReadWarning\n",
    "import logging\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Callable, Any\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "import json\n",
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "from getpass import getpass\n",
    "from dotenv import set_key\n",
    "from dotenv import load_dotenv\n",
    "from tavily import TavilyClient\n",
    "from langchain.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "from langchain.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    ToolMessage,\n",
    "    AnyMessage\n",
    ")\n",
    "import getpass\n",
    "from difflib import SequenceMatcher\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d5107c-793b-4fc1-b7bc-2653c16dd427",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "500d5e46-0b04-4f4a-856d-cdb88f2aba35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL = \"text-embedding-004\"\n",
    "LLM_MODEL = \"gemini-1.5-flash-001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e34e19f5-038b-4bea-8ac6-721536f0ee98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize Vertex AI\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "# Initialize Chroma client and collection\n",
    "embedding_function = VertexAIEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "\n",
    "# Initialize models\n",
    "llm = ChatVertexAI(model_name=LLM_MODEL, temperature=0, max_tokens = 4000)\n",
    "llm_calendar = ChatVertexAI(model_name=LLM_MODEL, temperature=.1, max_tokens=8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fd833fe-e117-462b-9511-4349daa5f4ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialize_system():\n",
    "    global global_chroma, chroma_client\n",
    "    \n",
    "    print(\"Initializing system...\")\n",
    "    chroma_client = chromadb.Client()\n",
    "    print(\"Getting or creating collection...\")\n",
    "    collection = chroma_client.get_or_create_collection(name=\"class_materials\")\n",
    "    \n",
    "    if collection.count() == 0:\n",
    "        print(\"Collection is empty, processing PDFs...\")\n",
    "        process_pdfs_from_gcs(BUCKET_NAME, PDF_FOLDER, collection)\n",
    "        print(\"PDF processing complete. Vector store updated.\")\n",
    "    else:\n",
    "        print(\"Using existing processed PDFs.\")\n",
    "    \n",
    "    print(\"Initializing global_chroma...\")\n",
    "    global_chroma = Chroma(\n",
    "        client=chroma_client,\n",
    "        collection_name=\"class_materials\",\n",
    "        embedding_function=embedding_function\n",
    "    )\n",
    "    print(\"System initialization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e95571f-f32d-4730-a49c-238f54f846ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter new database host (or press Enter to keep current):  \n",
      "Enter new database user (or press Enter to keep current):  \n",
      "Enter new database password (input hidden, or press Enter to keep current):  ········\n",
      "Enter new database name (or press Enter to keep current):  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from getpass import getpass #keep this import here\n",
    "\n",
    "new_db_host = input(\"Enter new database host (or press Enter to keep current): \")\n",
    "new_db_user = input(\"Enter new database user (or press Enter to keep current): \")\n",
    "new_db_password = getpass(\"Enter new database password (input hidden, or press Enter to keep current): \")\n",
    "new_db_database = input(\"Enter new database name (or press Enter to keep current): \")\n",
    "\n",
    "if new_db_host:\n",
    "    set_key(\".env\", \"DB_HOST\", new_db_host)\n",
    "if new_db_user:\n",
    "    set_key(\".env\", \"DB_USER\", new_db_user)\n",
    "if new_db_password:\n",
    "    set_key(\".env\", \"DB_PASSWORD\", new_db_password)\n",
    "if new_db_database:\n",
    "    set_key(\".env\", \"DB_DATABASE\", new_db_database)\n",
    "\n",
    "load_dotenv()  # Reload .env to get the new values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fffd926-4095-4d36-b04e-f9bfa98cd0b3",
   "metadata": {},
   "source": [
    "## PDF Querying Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d041806-20ef-4d0b-b4fa-1cc076e2d0b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_metadata_from_filename(filename):\n",
    "    parts = filename.split('_')\n",
    "    \n",
    "    # Determine course name\n",
    "    if filename.startswith(\"Marketing_Analytics\"):\n",
    "        course_name = \"Marketing Analytics\"\n",
    "        remaining_parts = parts[2:]\n",
    "    elif filename.startswith(\"Statistical_Analysis\"):\n",
    "        course_name = \"Statistical Analysis\"\n",
    "        remaining_parts = parts[2:]\n",
    "    elif filename.startswith(\"Introduction_to_Art_History\"):\n",
    "        course_name = \"Introduction to Art History\"\n",
    "        remaining_parts = parts[4:]\n",
    "    else:\n",
    "        course_name = \"Unknown Course\"\n",
    "        remaining_parts = parts\n",
    "\n",
    "    # Extract week information\n",
    "    week_number = \"\"\n",
    "    for i, part in enumerate(remaining_parts):\n",
    "        if part == \"Week\" and i + 1 < len(remaining_parts):\n",
    "            week_number = remaining_parts[i + 1]\n",
    "            break\n",
    "\n",
    "    # Determine document type and assignment number\n",
    "    document_type = \"Other\"\n",
    "    assignment_number = \"\"\n",
    "    if \"Assignment\" in filename:\n",
    "        document_type = \"Assignment\"\n",
    "        assignment_number = remaining_parts[-1].split('.')[0]\n",
    "    elif \"Lecture\" in filename:\n",
    "        document_type = \"Lecture Notes\"\n",
    "    elif \"Syllabus\" in filename:\n",
    "        document_type = \"Syllabus\"\n",
    "\n",
    "    return course_name, document_type, week_number, assignment_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95a398d8-ebf3-4482-8952-7423a51b0f8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_metadata(metadata):\n",
    "    \"\"\"Standardize metadata formatting while preserving all fields.\"\"\"\n",
    "    cleaned = {}\n",
    "    for k, v in metadata.items():\n",
    "        if k in ['course_name', 'document_type']:\n",
    "            cleaned[k] = str(v).lower() if v is not None else \"\"\n",
    "        elif k in ['week', 'assignment_number', 'page', 'source']:\n",
    "            cleaned[k] = str(v) if v is not None and v != \"\" else \"\"\n",
    "        else:\n",
    "            cleaned[k] = str(v) if v is not None else \"\"\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e32170e5-3650-4b79-b6c1-e81c17180fcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_pdfs_from_gcs(bucket_name, pdf_folder, collection):\n",
    "    global chroma_client\n",
    "    \n",
    "    storage_client = storage.Client(project=PROJECT_ID)\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blobs = bucket.list_blobs(prefix=pdf_folder)\n",
    "    \n",
    "    all_chunks = []\n",
    "    all_metadatas = []\n",
    "    all_ids = []\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=300)\n",
    "    \n",
    "    warnings.simplefilter(\"ignore\", PdfReadWarning)\n",
    "    warnings.filterwarnings(\"ignore\", message=\"Ignoring wrong pointing object\")\n",
    "    \n",
    "    logging.getLogger('PyPDF2').setLevel(logging.ERROR)\n",
    "    \n",
    "    for blob in blobs:\n",
    "        if blob.name.endswith(\".pdf\"):\n",
    "            filename = blob.name.split('/')[-1]\n",
    "            temp_file_path = f\"/tmp/{filename}\"\n",
    "            blob.download_to_filename(temp_file_path)\n",
    "            \n",
    "            try:\n",
    "                loader = PyPDFLoader(temp_file_path)\n",
    "                pages = loader.load_and_split()\n",
    "                \n",
    "                course_name, document_type, week_number, assignment_number = extract_metadata_from_filename(filename)\n",
    "                \n",
    "                for page in pages:\n",
    "                    chunks = text_splitter.split_text(page.page_content)\n",
    "                    all_chunks.extend(chunks)\n",
    "                    \n",
    "                    for chunk in chunks:\n",
    "                        chunk_id = str(uuid.uuid4())\n",
    "                        all_ids.append(chunk_id)\n",
    "                        \n",
    "                        raw_metadata = {\n",
    "                            \"source\": filename,\n",
    "                            \"page\": str(page.metadata.get('page', '')),\n",
    "                            \"course_name\": course_name,\n",
    "                            \"document_type\": document_type,\n",
    "                            \"week\": week_number,\n",
    "                            \"assignment_number\": assignment_number\n",
    "                        }\n",
    "                        \n",
    "                        cleaned_metadata = clean_metadata(raw_metadata)\n",
    "                        all_metadatas.append(cleaned_metadata)\n",
    "                \n",
    "                os.remove(temp_file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {filename}: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    if not all_chunks:\n",
    "        print(\"No valid chunks were extracted from the PDFs.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Extracted {len(all_chunks)} chunks.\")\n",
    "    \n",
    "    # Generate embeddings\n",
    "    embeddings = VertexAIEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "    embedded_chunks = []\n",
    "    for i, chunk in enumerate(all_chunks):\n",
    "        try:\n",
    "            embedding = embeddings.embed_query(chunk)\n",
    "            embedded_chunks.append(embedding)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to embed chunk {i}: {str(e)}\")\n",
    "            print(f\"Chunk content: {chunk[:100]}...\")\n",
    "    \n",
    "    print(f\"Generated {len(embedded_chunks)} embeddings.\")\n",
    "    \n",
    "    if len(all_chunks) != len(embedded_chunks):\n",
    "        print(\"Warning: Number of chunks doesn't match number of embeddings.\")\n",
    "        print(\"Chunks without embeddings:\")\n",
    "        for i, chunk in enumerate(all_chunks):\n",
    "            if i >= len(embedded_chunks):\n",
    "                print(f\"Chunk {i}: {chunk[:250]}...\")\n",
    "    \n",
    "    # Ensure all lists have the same length\n",
    "    min_length = min(len(all_ids), len(embedded_chunks), len(all_metadatas), len(all_chunks))\n",
    "    all_ids = all_ids[:min_length]\n",
    "    embedded_chunks = embedded_chunks[:min_length]\n",
    "    all_metadatas = all_metadatas[:min_length]\n",
    "    all_chunks = all_chunks[:min_length]\n",
    "    \n",
    "    print(f\"Final count: {min_length} items.\")\n",
    "    \n",
    "    # Add to the existing Chroma collection\n",
    "    try:\n",
    "        collection.add(\n",
    "            ids=all_ids,\n",
    "            embeddings=embedded_chunks,\n",
    "            metadatas=all_metadatas,\n",
    "            documents=all_chunks\n",
    "        )\n",
    "        print(f\"Added {min_length} chunks to the collection.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error adding documents to collection: {str(e)}\")\n",
    "        print(\"First few metadatas for debugging:\")\n",
    "        for metadata in all_metadatas[:5]:\n",
    "            print(metadata)\n",
    "    \n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cba2c26-724b-4780-8aa3-69b9e04fb6b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_details_llm(query, llm_model):\n",
    "    llm_prompt = (\n",
    "        f\"Analyze the following query and extract the course name, document type, week number, and assignment number (if mentioned). \"\n",
    "        f\"The course name will be one of 'Marketing Analytics', 'Statistical Analysis', or 'Introduction to Art History'. \"\n",
    "        f\"The document type could be 'Assignment', 'Lecture Notes', 'Syllabus', or any other relevant type. \"\n",
    "        f\"The week number should be specifically extracted if mentioned (e.g., from 'Week 1' only '1' should be returned). \"\n",
    "        f\"The assignment number should be extracted if mentioned (e.g., e.g., from 'Assignment 1' only '1' should be returned). \"\n",
    "        f\"If the query doesn't specify certain details, leave them blank. \"\n",
    "        f\"Respond with the course name, document type, week number, and assignment number separated by commas.\\n\\n\"\n",
    "        f\"Query: {query}\\n\\nResponse (Course Name, Document Type, Week Number, Assignment Number):\"\n",
    "    )\n",
    "    response = llm_model.predict(llm_prompt)\n",
    "    response = response.strip()\n",
    "    \n",
    "    parts = response.split(',')\n",
    "    course_name = parts[0].strip() if len(parts) > 0 else \"\"\n",
    "    document_type = parts[1].strip() if len(parts) > 1 else \"\"\n",
    "    week_number = parts[2].strip() if len(parts) > 2 else \"\"\n",
    "    assignment_number = parts[3].strip() if len(parts) > 3 else \"\"\n",
    "\n",
    "    return course_name, document_type, week_number, assignment_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a06aa5ac-e920-4387-9dee-5e8d9bf719a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_response(query, context, llm):\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI assistant for university courses including Marketing Analytics, Statistical Analysis, and Introduction to Art History. You have been given the following context information from course materials:\n",
    "\n",
    "    {context}\n",
    "\n",
    "    Based on this context, please answer the following question:\n",
    "\n",
    "    {query}\n",
    "\n",
    "    If the answer is not explicitly stated in the context, use your knowledge to provide a relevant response, but make it clear that this information is not directly from the course materials.\n",
    "\n",
    "    Your response should be:\n",
    "    1. Accurate based on the given context\n",
    "    2. Concise yet informative\n",
    "    3. Structured in a clear, easy-to-read format\n",
    "    4. Tailored to the specific course (Marketing Analytics, Statistical Analysis, or Introduction to Art History) when applicable\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.predict(prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8201a273-bf31-4ebb-94de-0c417e6ff535",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_collection(query, top_k=5):\n",
    "    global global_chroma\n",
    "    \n",
    "    course_name, document_type, week_number, assignment_number = extract_details_llm(query, llm)\n",
    "    print(f\"Extracted - Course: {course_name}, Type: {document_type}, Week: {week_number}, Assignment: {assignment_number}\")\n",
    "    \n",
    "    filter_conditions = []\n",
    "    if course_name:\n",
    "        filter_conditions.append({\"course_name\": {\"$eq\": course_name.lower()}})\n",
    "    if document_type:\n",
    "        filter_conditions.append({\"document_type\": {\"$eq\": document_type.lower()}})\n",
    "    if week_number:\n",
    "        filter_conditions.append({\"week\": {\"$eq\": week_number}})\n",
    "    if assignment_number:\n",
    "        filter_conditions.append({\"assignment_number\": {\"$eq\": assignment_number}})\n",
    "    \n",
    "    if len(filter_conditions) > 1:\n",
    "        filter_dict = {\"$and\": filter_conditions}\n",
    "    elif len(filter_conditions) == 1:\n",
    "        filter_dict = filter_conditions[0]\n",
    "    else:\n",
    "        filter_dict = {}\n",
    "    \n",
    "    print(f\"Using filter: {filter_dict}\")\n",
    "    \n",
    "    try:\n",
    "        results = global_chroma.similarity_search_with_score(\n",
    "            query,\n",
    "            k=top_k,\n",
    "            filter=filter_dict\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error during similarity search: {str(e)}\")\n",
    "        return \"An error occurred while searching for relevant information.\"\n",
    "    \n",
    "    if not results:\n",
    "        # If no results, try a more relaxed search\n",
    "        relaxed_filter = {\"course_name\": {\"$eq\": course_name.lower()}} if course_name else {}\n",
    "        try:\n",
    "            results = global_chroma.similarity_search_with_score(\n",
    "                query,\n",
    "                k=top_k,\n",
    "                filter=relaxed_filter\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error during relaxed similarity search: {str(e)}\")\n",
    "            return \"An error occurred while searching for relevant information.\"\n",
    "    \n",
    "    if not results:\n",
    "        return \"No relevant information found in the course documents.\"\n",
    "    \n",
    "    context = \"\\n\\n\".join([f\"Source: {doc.metadata['source']}, Page: {doc.metadata['page']}\\n{doc.page_content}\" for doc, _ in results])\n",
    "    response = generate_response(query, context, llm)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3497fe-b4ee-4c7f-ac7f-a3e107c895dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## *Tool for Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86ca1b84-675c-46b2-b45c-6bc040fb74bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def pdf_rag_query(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Query PDF documents for course information, assignments, and lecture content.\n",
    "    \n",
    "    Args:\n",
    "        query: The question or query about course materials.\n",
    "    \n",
    "    Returns:\n",
    "        A response based on the information found in the course PDFs.\n",
    "    \"\"\"\n",
    "    # The query_collection function handles db initialization and querying\n",
    "    response = query_collection(query)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9b4f56-b9c3-4cfb-95ce-4822927f91e0",
   "metadata": {},
   "source": [
    "## Calendar Querying Logic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "deb9a489-ac27-447c-b538-5199a8b15785",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_events():\n",
    "    # Get database connection details from environment variables\n",
    "    db_host = os.getenv(\"DB_HOST\")\n",
    "    db_user = os.getenv(\"DB_USER\")\n",
    "    db_password = os.getenv(\"DB_PASSWORD\")\n",
    "    db_database = os.getenv(\"DB_DATABASE\")\n",
    "\n",
    "    try:\n",
    "        # Establish database connection\n",
    "        mydb = mysql.connector.connect(\n",
    "            host=db_host,\n",
    "            user=db_user,\n",
    "            password=db_password,\n",
    "            database=db_database\n",
    "        )\n",
    "        \n",
    "        # Create cursor\n",
    "        cursor = mydb.cursor()\n",
    "        \n",
    "        # Execute the SELECT query with ordering\n",
    "        query = \"\"\"\n",
    "        SELECT events_json\n",
    "        FROM events\n",
    "        WHERE is_deleted = 0\n",
    "        ORDER BY COALESCE(start_time, due_date) ASC\n",
    "        \"\"\"\n",
    "        \n",
    "        cursor.execute(query)\n",
    "        \n",
    "        # Fetch all rows\n",
    "        rows = cursor.fetchall()\n",
    "        \n",
    "        formatted_events = []\n",
    "        for row in rows:\n",
    "            events_json = row[0]\n",
    "            event_dict = json.loads(events_json)\n",
    "            formatted_events.append(json.dumps(event_dict))\n",
    "        \n",
    "        # Join formatted events with double newlines\n",
    "        return \"\\n\\n\".join(formatted_events)\n",
    "\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Something went wrong: {err}\")\n",
    "        return None\n",
    "\n",
    "    finally:\n",
    "        # Close cursor and connection\n",
    "        if 'cursor' in locals():\n",
    "            cursor.close()\n",
    "        if 'mydb' in locals():\n",
    "            mydb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebc0ac2b-a413-4378-95e0-adc0b783ac71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the events context\n",
    "events_context = get_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65c197d8-7109-4efa-8af8-169222c452f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_calendar(query, llm):\n",
    "    \n",
    "    # Get current date and time\n",
    "    current_datetime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Format the context with a header and code block\n",
    "    formatted_context = f\"\"\"\n",
    "    \n",
    "    This is the current date and time: {current_datetime}\n",
    "    \n",
    "    Below is a list of events in the student's calendar, ordered chronologically. Each event is represented as a JSON object:\n",
    "\n",
    "    ```\n",
    "    {events_context}\n",
    "    ```\n",
    "    \n",
    "    All events have the following fields:\n",
    "    - tag: The type of event (class, personal, study time, quiz, discussion, or assignment)\n",
    "    - title: The title of the event\n",
    "    - eventDuration: The duration of the event in minutes \n",
    "    - description: A description of the event (if available)\n",
    "\n",
    "    Each assigment, quiz, or discussion could have the following additional fields: \n",
    "    - due_date: The due date (for assignment type events)\n",
    "    - instructions: instructions for the academic activity \n",
    "    \n",
    "    Each event that is not an assignment, quiz, or discussion has the following fields:\n",
    "    - startTime: The start time of the event (for non-assignment type events)\n",
    "    - endTime: The end time of the event (for non-assignment type events)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an AI assistant for a student calendar management system. You have been provided with the following context, which contains information about the student's events in chronological order:\n",
    "\n",
    "    {formatted_context}\n",
    "\n",
    "    Based on this context, please answer the following question:\n",
    "    {query}\n",
    "\n",
    "    Guidelines for your response:\n",
    "    1. Provide accurate information based on the given context.\n",
    "    2. If the exact answer isn't in the context, use your knowledge to give a relevant response, but clearly state that it's not directly from the calendar data.\n",
    "    3. Remember that the events are already in chronological order with some events in the past and some in the future. \n",
    "    4. For assignment-type events, use the due_date field. For other events, use startTime and endTime.\n",
    "    5. If asked about free time or scheduling, consider the startTime and endTime of events.\n",
    "    6. Offer helpful suggestions or insights based on the student's schedule when appropriate.\n",
    "    7. Keep your response concise yet informative.\n",
    "    8. If you need more information to answer accurately, ask for clarification.\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.predict(prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df37dcd1-0097-4aa5-afcb-e3398db6ee4c",
   "metadata": {},
   "source": [
    "## *Tool for Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a7532c5-5193-43c6-b633-2e6a9e3473f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def calendar_query(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Query the student's calendar for information about events, classes, assignments, and schedule.\n",
    "    \n",
    "    Args:\n",
    "        query: The question or query about the student's calendar and schedule.\n",
    "    \n",
    "    Returns:\n",
    "        A response based on the information found in the student's calendar.\n",
    "    \"\"\"\n",
    "    response = query_calendar(query, llm_calendar)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805053e6-d293-4924-b1c2-043bfdd74bb1",
   "metadata": {},
   "source": [
    "# Tavily Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fa100d3-dbf4-4994-99a4-069b85988ad1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def content_recommendations(query: str) -> str:\n",
    "    tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "    tavily_client = TavilyClient(api_key=tavily_api_key)\n",
    "\n",
    "    search_query = f\"What are some highly recommended, freely accessible resources to learn about {query}? Focus on reputable blog posts, open-access articles, and educational websites.\"\n",
    "\n",
    "    response = tavily_client.search(search_query, search_depth=\"basic\", include_answer=True, max_results=3)\n",
    "\n",
    "    recommendations = f\"Here are some recommended resources based on a few keywords taken from the content: {query}:\\n\\n\"\n",
    "\n",
    "    for i, result in enumerate(response['results'], 1):\n",
    "        logger.info(f\"Processing result {i}: {result}\")\n",
    "        \n",
    "        title = result.get('title', 'No title available')\n",
    "        url = result.get('url', 'No URL available')\n",
    "        content = result.get('content', 'No content available')\n",
    "        score = result.get('score', 0.0)\n",
    "\n",
    "        recommendations += f\"{i}. {title} (Relevance: {score:.2f})\\n\"\n",
    "        recommendations += f\"   URL: {url}\\n\"\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1581a45e-cee0-4fc0-89e1-224973e48b30",
   "metadata": {},
   "source": [
    "# Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e627e28-ef02-4ff0-be95-38a40df90b5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_content_recommendations(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Get content recommendations for learning about a specific subject.\n",
    "    \n",
    "    Args:\n",
    "        query: The subject or topic the user wants to learn about.\n",
    "    \n",
    "    Returns:\n",
    "        A string containing relevant links and brief descriptions of recommended resources.\n",
    "    \"\"\"\n",
    "    recommendations = content_recommendations(query)\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246e5f38-78ef-43b6-8ddb-c0a1fee959e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b1adcef-1560-4afa-9bce-3f8d4c7742d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6a9d602-c056-419c-a3c0-8ca31cf9d62a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "edca7131-720e-446a-a4cb-90c40dd7d04b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, checkpointer, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_gemini)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\n",
    "            \"llm\",\n",
    "            self.exists_action,\n",
    "            {True: \"action\", False: END}\n",
    "        )\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(checkpointer = checkpointer)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "        \n",
    "    def log_state(self, state: AgentState, location: str):\n",
    "        print(f\"\\n--- State at {location} ---\")\n",
    "        print(f\"Number of messages: {len(state['messages'])}\")\n",
    "        print(f\"Last message type: {type(state['messages'][-1])}\")\n",
    "        if isinstance(state['messages'][-1], ToolMessage):\n",
    "            print(f\"Last tool used: {state['messages'][-1].name}\")\n",
    "            print(f\"Tool result: {state['messages'][-1].content}...\")  # First 100 chars\n",
    "        elif hasattr(state['messages'][-1], 'tool_calls'):\n",
    "            print(f\"Tool calls: {state['messages'][-1].tool_calls}\")\n",
    "        print(\"------------------------\\n\")\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        self.log_state(state, \"exists_action\")\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def call_gemini(self, state: AgentState):\n",
    "        self.log_state(state, \"call_gemini (before)\")\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        new_state = {'messages': [message]}\n",
    "        self.log_state(new_state, \"call_gemini (after)\")\n",
    "        return new_state\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        self.log_state(state, \"take_action (before)\")\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            if t['name'] not in self.tools:\n",
    "                print(\"\\n....bad tool name....\")\n",
    "                result = \"bad tool name, retry\"\n",
    "            else:\n",
    "                result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        new_state = {'messages': results}\n",
    "        self.log_state(new_state, \"take_action (after)\")\n",
    "        return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41d2dfa2-8497-405f-9b74-14783c92037c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_datetime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9eb6572b-09a2-422b-9ee0-e203113a4efb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing system...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting or creating collection...\n",
      "Collection is empty, processing PDFs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 38 chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.api.segment:Collection class_materials is not created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 38 embeddings.\n",
      "Final count: 38 items.\n",
      "Added 38 chunks to the collection.\n",
      "PDF processing complete. Vector store updated.\n",
      "Initializing global_chroma...\n",
      "System initialization complete.\n"
     ]
    }
   ],
   "source": [
    "initialize_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11b05224-71e4-4966-a8c9-5c3b984e75b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Current datetime: {agent_datetime}\n",
    "You are an AI assistant supporting university students. Your primary goal is to provide comprehensive, helpful responses by effectively utilizing the following tools:\n",
    "\n",
    "1. pdf_rag_query: Retrieves content from course documents (assignments, lecture notes, syllabi).\n",
    "   - USE THIS TOOL FIRST for any query about specific course content, including lecture notes, assignments, or syllabus information.\n",
    "   - Utilizes for query: course name, assignment number, week number, and document type (lecture notes, assignment, syllabus).\n",
    "   - Example query: \"Marketing Analytics Assignment 4 instructions\" or \"Week 3 Lecture Notes Statistical Analysis\"\n",
    "\n",
    "2. calendar_query: Searches through calendar events (classes, assignments, discussions and discussion content, personal events).\n",
    "   - USE THIS TOOL ONLY for queries about schedules, deadlines, upcoming events, or when a student asks \"what do I have\" or \"when is something due\".\n",
    "   - Example query: \"next due assignment\" or \"upcoming Marketing Analytics classes\" or \"what do I have due today?\"\n",
    "\n",
    "3. get_content_recommendations: Web search tool for finding relevant educational resources.\n",
    "   - USE THIS TOOL ONLY after gathering specific information from pdf_rag_query or when explicitly asked for external resources.\n",
    "   - Use (only) 2 key terms or concepts for the web search.\n",
    "   - Example query: \"predictive modeling, optimization analysis\"\n",
    "\n",
    "DECISION-MAKING FRAMEWORK:\n",
    "1. Carefully analyze the student's query. Identify the specific information needed to provide a complete answer.\n",
    "2. Think and determine the most appropriate tool(s) for the query based on these guidelines:\n",
    "   - If the query is about course content (lectures, assignments, syllabus), use pdf_rag_query FIRST.\n",
    "   - If the query is about schedules or deadlines, use calendar_query.\n",
    "   - If the query is about finding external resources, use get_content_recommendations AFTER using pdf_rag_query if needed.\n",
    "3. Plan your approach step by step:\n",
    "   a. Decide which tool(s) to use and in what order.\n",
    "   b. Consider how information from one tool might inform the use of another.\n",
    "4. Use tools ONE AT A TIME, in the most logical order to answer the query comprehensively.\n",
    "5. For each tool use:\n",
    "   a. Formulate specific queries based on the student's question and any previously gathered information.\n",
    "   b. Include relevant course names, assignment numbers, or key concepts as needed.\n",
    "6. After each tool use, evaluate:\n",
    "   a. Review the information received.\n",
    "   b. Have you gathered all necessary information?\n",
    "   c. Do you need to use additional tools based on this new information?\n",
    "   d. Can you now provide a comprehensive answer?\n",
    "7. If another tool is needed, formulate the next query based on all information gathered so far.\n",
    "8. Only proceed to the next tool after fully processing the results of the previous tool.\n",
    "9. For get_content_recommendations, always base your search terms on concrete information from the query or previous tool results, not assumptions.\n",
    "\n",
    "EXAMPLES OF TOOL USAGE PATTERNS:\n",
    "1. For \"Can you give me some resources for the next assignment?\":\n",
    "   - Use calendar_query to identify the next assignment\n",
    "   - Then use pdf_rag_query to get details about that assignment\n",
    "   - Finally use get_content_recommendations with key terms from the assignment details\n",
    "\n",
    "2. For \"What resources would you recommend based on marketing analytics assignment 2?\":\n",
    "   - First use pdf_rag_query to get the content of Marketing Analytics Assignment 2\n",
    "   - Review the assignment content\n",
    "   - Then use get_content_recommendations with 2 key concepts from the actual assignment content\n",
    "\n",
    "Remember: Each query is unique. Adapt your tool usage based on the specific information needed. Process tools sequentially, using the output of one to inform the use of the next if needed. Do not call multiple tools simultaneously.\n",
    "\n",
    "RESPONSE GUIDELINES:\n",
    "1. Address the student directly in a helpful, encouraging manner.\n",
    "2. Provide a clear, structured response that answers all aspects of the query.\n",
    "3. Explain your reasoning if you've made any assumptions or interpretations.\n",
    "4. Encourage the student to explore recommended resources when applicable.\n",
    "5. Please include all tool responses in the final response.\n",
    "\n",
    "Always prioritize providing the most relevant and helpful information to the student based on their specific query and the actual information gathered from the tools.\n",
    "\"\"\"\n",
    "\n",
    "agent = Agent(llm_calendar, [pdf_rag_query, calendar_query, get_content_recommendations], system=prompt, checkpointer = memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1aefead8-3d6d-49cf-a59e-a1b696ac4777",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def should_start_new_thread(previous_query: str, current_query: str) -> bool:\n",
    "    # Check if the queries are similar\n",
    "    similarity = SequenceMatcher(None, previous_query.lower(), current_query.lower()).ratio()\n",
    "    \n",
    "    # Check if the current query is a follow-up question\n",
    "    follow_up_patterns = [\n",
    "        r\"^(what|how) about\",\n",
    "        r\"^and \",\n",
    "        r\"^also\",\n",
    "        r\"^additionally\",\n",
    "        r\"^moreover\",\n",
    "        r\"^furthermore\",\n",
    "        r\"^in addition\",\n",
    "    ]\n",
    "    \n",
    "    is_follow_up = any(re.match(pattern, current_query.lower()) for pattern in follow_up_patterns)\n",
    "    \n",
    "    # Start a new thread if the queries are not similar and it's not a follow-up question\n",
    "    return similarity < 0.7 and not is_follow_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef98603c-077e-4f5d-94af-a869015c62f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "last_query = \"\"\n",
    "current_thread_id = str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21e7b509-fb97-4718-a98f-70a965d693d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_query(query: str) -> str:\n",
    "    global last_query, current_thread_id\n",
    "    \n",
    "    if should_start_new_thread(last_query, query):\n",
    "        current_thread_id = str(uuid.uuid4())\n",
    "        print(f\"Starting new thread with ID: {current_thread_id}\")\n",
    "    \n",
    "    \n",
    "    messages = [HumanMessage(content=query)]\n",
    "    thread = {\"configurable\": {\"thread_id\": current_thread_id}}\n",
    "    result = agent.graph.invoke({\"messages\": messages}, thread)\n",
    "    \n",
    "    # Extract the calendar query response and content recommendations\n",
    "    calendar_response = \"\"\n",
    "    content_recommendations = \"\"\n",
    "    pdf_rag_response = \"\"\n",
    "    \n",
    "    tool_responses_found = False\n",
    "    \n",
    "    for message in result['messages']:\n",
    "        if isinstance(message, ToolMessage):\n",
    "            tool_responses_found = True\n",
    "            if message.name == 'calendar_query':\n",
    "                calendar_response = message.content\n",
    "            elif message.name == 'get_content_recommendations':\n",
    "                content_recommendations = message.content\n",
    "            elif message.name == 'pdf_rag_query':\n",
    "                pdf_rag_response = message.content\n",
    "    \n",
    "    if tool_responses_found:\n",
    "        # Combine the responses if tools were used\n",
    "        final_response = f\"{calendar_response}\\n\\n{pdf_rag_response}\\n\\n{content_recommendations}\".strip()\n",
    "    else:\n",
    "        # Use the agent's direct response if no tools were used\n",
    "        final_response = result['messages'][-1].content\n",
    "    \n",
    "    # Update the last query\n",
    "    last_query = query\n",
    "    \n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b414c0e-b7ed-46a4-8729-ed5059a1582c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: what's my next event?\n",
      "Starting new thread with ID: 4aeec1de-bfc1-466f-b559-2aaf14542636\n",
      "\n",
      "--- State at call_gemini (before) ---\n",
      "Number of messages: 1\n",
      "Last message type: <class 'langchain_core.messages.human.HumanMessage'>\n",
      "------------------------\n",
      "\n",
      "\n",
      "--- State at call_gemini (after) ---\n",
      "Number of messages: 1\n",
      "Last message type: <class 'langchain_core.messages.ai.AIMessage'>\n",
      "Tool calls: [{'name': 'calendar_query', 'args': {'query': 'next event'}, 'id': '053cf8b0-5a9b-41ca-8e09-73098873a78d', 'type': 'tool_call'}]\n",
      "------------------------\n",
      "\n",
      "\n",
      "--- State at exists_action ---\n",
      "Number of messages: 2\n",
      "Last message type: <class 'langchain_core.messages.ai.AIMessage'>\n",
      "Tool calls: [{'name': 'calendar_query', 'args': {'query': 'next event'}, 'id': '053cf8b0-5a9b-41ca-8e09-73098873a78d', 'type': 'tool_call'}]\n",
      "------------------------\n",
      "\n",
      "\n",
      "--- State at take_action (before) ---\n",
      "Number of messages: 2\n",
      "Last message type: <class 'langchain_core.messages.ai.AIMessage'>\n",
      "Tool calls: [{'name': 'calendar_query', 'args': {'query': 'next event'}, 'id': '053cf8b0-5a9b-41ca-8e09-73098873a78d', 'type': 'tool_call'}]\n",
      "------------------------\n",
      "\n",
      "Calling: {'name': 'calendar_query', 'args': {'query': 'next event'}, 'id': '053cf8b0-5a9b-41ca-8e09-73098873a78d', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "\n",
      "--- State at take_action (after) ---\n",
      "Number of messages: 1\n",
      "Last message type: <class 'langchain_core.messages.tool.ToolMessage'>\n",
      "Last tool used: calendar_query\n",
      "Tool result: The next event is **\"Class: Introduction to Art History \"** starting at **2024-08-01T09:00:00**. \n",
      "...\n",
      "------------------------\n",
      "\n",
      "\n",
      "--- State at call_gemini (before) ---\n",
      "Number of messages: 3\n",
      "Last message type: <class 'langchain_core.messages.tool.ToolMessage'>\n",
      "Last tool used: calendar_query\n",
      "Tool result: The next event is **\"Class: Introduction to Art History \"** starting at **2024-08-01T09:00:00**. \n",
      "...\n",
      "------------------------\n",
      "\n",
      "\n",
      "--- State at call_gemini (after) ---\n",
      "Number of messages: 1\n",
      "Last message type: <class 'langchain_core.messages.ai.AIMessage'>\n",
      "Tool calls: []\n",
      "------------------------\n",
      "\n",
      "\n",
      "--- State at exists_action ---\n",
      "Number of messages: 4\n",
      "Last message type: <class 'langchain_core.messages.ai.AIMessage'>\n",
      "Tool calls: []\n",
      "------------------------\n",
      "\n",
      "Response:\n",
      "The next event is **\"Class: Introduction to Art History \"** starting at **2024-08-01T09:00:00**.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test_queries = [\n",
    "        \"\"\"what's my next event?\"\"\"\n",
    "    ]\n",
    "\n",
    "\n",
    "    for query in test_queries:\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        response = process_query(query)\n",
    "        print(f\"Response:\\n{response}\")\n",
    "        print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m119"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
